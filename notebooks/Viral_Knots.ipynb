{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b83adb58",
   "metadata": {},
   "outputs": [],
   "source": [
    "from Bio import SeqIO\n",
    "import arnie\n",
    "from arnie.pk_predictors import pk_predict\n",
    "from arnie.utils import *\n",
    "from arnie.utils import _group_into_non_conflicting_bp\n",
    "import pandas as pd\n",
    "\n",
    "def get_seq(seq_filename):\n",
    "    record = SeqIO.read(seq_filename, \"fasta\")\n",
    "    return str(record.seq)\n",
    "\n",
    "def get_sliding_windows(full_seq, step, window):\n",
    "    coords = list(range(0,len(full_seq)-window+1,step))\n",
    "    windows = []\n",
    "    for i in coords:\n",
    "        new_window = full_seq[i:i+window]\n",
    "        windows.append(new_window)\n",
    "    return windows, coords\n",
    "\n",
    "def stable_helices(dotbracket):\n",
    "    bp_list = convert_dotbracket_to_bp_list(dotbracket, allow_pseudoknots=True)\n",
    "    groups = _group_into_non_conflicting_bp(bp_list)\n",
    "    for idx, pairs in enumerate(groups):\n",
    "        if idx > 0:\n",
    "            if len(pairs) == 1:\n",
    "                return False \n",
    "            \n",
    "def get_pseudoknots(seq_windows, coords, pk_predictor):\n",
    "    PK_list = []\n",
    "    for seq,coord in zip(seq_windows,coords):\n",
    "        dotbracket = pk_predict(seq, pk_predictor)\n",
    "        if is_PK(dotbracket):\n",
    "            if stable_helices(dotbracket):\n",
    "                PK_list.append([coord, coord+window, seq, dotbracket])\n",
    "    df = pd.DataFrame(PK_list,columns=[\"start\",\"end\",\"sequence\", \"struct\"])\n",
    "    return df\n",
    "\n",
    "#input is list of shape values as floats with nan values numpy objects \n",
    "def normalize_shape(shape_reacs):\n",
    "    shape_reacs = np.array(shape_reacs)\n",
    "\n",
    "    # Get rid of nan values for now\n",
    "    nonan_shape_reacs = shape_reacs[~np.isnan(shape_reacs)]\n",
    "\n",
    "    # Find Filter 1: 1.5 * Inter-Quartile Range\n",
    "    sorted_shape = np.sort(nonan_shape_reacs)\n",
    "    q1 = sorted_shape[int(0.25 * len(sorted_shape))]\n",
    "    q3 = sorted_shape[int(0.75 * len(sorted_shape))]\n",
    "    iq_range = abs(q3 - q1)\n",
    "    filter1 = next(x for x, val in \\\n",
    "        enumerate(list(sorted_shape)) if val > 1.5 * iq_range)\n",
    "\n",
    "    # Find Filter 2: 95% value\n",
    "    filter2 = int(0.95 * len(sorted_shape))\n",
    "\n",
    "    # Get maximum filter value and fiter data\n",
    "    filter_cutoff = sorted_shape[max(filter1, filter2)]\n",
    "    sorted_shape = sorted_shape[sorted_shape < filter_cutoff]\n",
    "\n",
    "    # Scalefactor: Mean of top 10th percentile of values\n",
    "    top90 = sorted_shape[int(0.9 * len(sorted_shape))]\n",
    "    scalefactor = np.mean(sorted_shape[sorted_shape > top90])\n",
    "        \n",
    "    # Scale dataset\n",
    "    return shape_reacs/scalefactor\n",
    "\n",
    "# input is text file of any shape data set, output is normalized list of values in a list (some np.nan objects)\n",
    "def retrieve_shape_data(shape_filename):\n",
    "\n",
    "    # write shape text file to list\n",
    "    shape_file = open(\"{}\".format(shape_filename), \"r\")\n",
    "    shape_data = shape_file.read()\n",
    "    shape_data_list = shape_data.split(\"\\n\")\n",
    "    shape_file.close()\n",
    "    \n",
    "    shape_nan_list = []\n",
    "    for char in shape_data_list:\n",
    "        if char == '':\n",
    "            shape_data_list.remove('')\n",
    "        elif (char == '-999') or (char == 'nan') or (char == \"NaN\"):\n",
    "            shape_nan_list.append('nan')\n",
    "        else: \n",
    "            shape_nan_list.append(float(char))\n",
    "    \n",
    "    #convert string 'nan' to np.nan\n",
    "    shape_reacs = []\n",
    "    for char in shape_nan_list:\n",
    "        if char == 'nan':\n",
    "            shape_reacs.append(np.nan)\n",
    "        else:\n",
    "            shape_reacs.append(char)\n",
    "    \n",
    "    # normalize shape data\n",
    "    normalized_shape_data = normalize_shape(shape_reacs).tolist()\n",
    "    return normalized_shape_data\n",
    "\n",
    "#add in this capability later\n",
    "#def get_pseudoknots_with_shapeknots()\n",
    "\n",
    "def viral_knots(seq_filename, shapeknots=False, shape_rankings=False, shape_data_folder=None, \n",
    "                shape_data_sets=None, pk_predictors, step, window):\n",
    "    ### args:\n",
    "        ### seq_filename - fasta file containing RNA sequence for viral genome\n",
    "        ### shapeknots - if shapeknots is one of the predictors desired to use (must include shape data)\n",
    "        ### shape_rankings - if shape reactivity values are used to score the pseudoknots (must include shape data)\n",
    "        ### shape_data_folder - folder containing csv's with shape reactivity\n",
    "        ### shape_data_sets - names of the reactivity files (no .csv necessary)\n",
    "        ### pk_predictors - list of desired predictors for use: currently implemented are threshknots, knotty, pknots, spotrna\n",
    "        ### step - desired number of nucleotides to slide each window\n",
    "        ### window - desired size of window to divide genome into\n",
    "    \n",
    "    \n",
    "    ##first retrieve viral sequence and shape data (if directed)\n",
    "    seq = get_seq(seq_filename)\n",
    "    RNA_seq = seq.replace(\"T\", \"U\")\n",
    "    \n",
    "    ##sort sequence and normalized shape data into windows\n",
    "    \n",
    "    seq_windows, coords = get_sliding_windows(RNA_seq, step=step, window=window)\n",
    "    \n",
    "    all_shape_windows = []\n",
    "    if shapeknots or shape_rankings:\n",
    "        shape_reacs = []\n",
    "        for name in shape_data_sets:\n",
    "            shape_reacs.append(retrieve_shape_data(shape_data_folder+'/'+name+'.csv'))\n",
    "            \n",
    "        for track in shape_reacs:\n",
    "            shape_windows, shape_coords = get_sliding_windows(track, step=step, window=window)\n",
    "            all_shape_windows.append(shape_windows)\n",
    "    \n",
    "    ##run necessary data through each predictor and sort output into individual csvs\n",
    "    \n",
    "    pk_dfs = []\n",
    "    for name in pk_predictors:\n",
    "        pk_dfs.append(get_pseudoknots(seq_windows, coords, pk_predictor=name))\n",
    "    \n",
    "    ##run shapeknots - once implemented\n",
    "    \n",
    "    #shapeknots_dfs = []\n",
    "    #if shapeknots:\n",
    "        #shapeknots_dfs.append(run_shapeknots(...))\n",
    "    \n",
    "    ##run csv's through ranking function - output is sorted in csv containing program, location, \n",
    "        #sequence, structure, consensus, shape score, and free energy \n",
    "    \n",
    "    \n",
    "    \n",
    "    #output is single csv containing: location, sequence, average consensus for that window\n",
    "        #average consensus for pseudoknotted base pairs\n",
    "        #list of predictors and corresponding structures\n",
    "        #z_scores for each structure (average across all predicted structures?)\n",
    "            #to use arnie function, must use either nupack or threshknot+contrafold+linearpartition\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c38e903a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>start</th>\n",
       "      <th>end</th>\n",
       "      <th>sequence</th>\n",
       "      <th>struct</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>160</td>\n",
       "      <td>UUUCGAUCUCUUGUAGAUCUGUUCUCUAAACGAACUUUAAAAUCUG...</td>\n",
       "      <td>....(((((.....))))).........................(....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>120</td>\n",
       "      <td>240</td>\n",
       "      <td>CACGCAGUAUAAUUAAUAACUAAUUACUGUCGUUGACAGGACACGA...</td>\n",
       "      <td>.((....((..(((.......)))))[[[[[)).]]]]]...((((...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>360</td>\n",
       "      <td>480</td>\n",
       "      <td>AGACUCCGUGGAGGAGGUCUUAUCAGAGGCACGUCAACAUCUUAAA...</td>\n",
       "      <td>((((((([[[..)))).))).........]]].....((((((.))...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>400</td>\n",
       "      <td>520</td>\n",
       "      <td>CUUAAAGAUGGCACUUGUGGCUUAGUAGAAGUUGAAAAAGGCGUUU...</td>\n",
       "      <td>......((.....(....((((......((((((....(((((......</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>440</td>\n",
       "      <td>560</td>\n",
       "      <td>GCGUUUUGCCUCAACUUGAACAGCCCUAUGUGUUCAUCAAACGUUC...</td>\n",
       "      <td>.((((.[[[[.[[[[[((((((........))))))...))))......</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>334</th>\n",
       "      <td>334</td>\n",
       "      <td>29480</td>\n",
       "      <td>29600</td>\n",
       "      <td>UCUCCAAACAAUUGCAACAAUCCAUGAGCAGUGCUGACUCAACUCA...</td>\n",
       "      <td>............(.........[[[[[[[)...(((((....))))...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>335</th>\n",
       "      <td>335</td>\n",
       "      <td>29520</td>\n",
       "      <td>29640</td>\n",
       "      <td>AACUCAGGCCUAAACUCAUGCAGACCACACAAGGCAGAUGGGCUAU...</td>\n",
       "      <td>...........................(((((((....((((((((...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>336</th>\n",
       "      <td>336</td>\n",
       "      <td>29560</td>\n",
       "      <td>29680</td>\n",
       "      <td>GGCUAUAUAAACGUUUUCGCUUUUCCGUUUACGAUAUAUAGUCUAC...</td>\n",
       "      <td>((((((((((([[[.............)).]]].)))))))))(.....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>337</th>\n",
       "      <td>337</td>\n",
       "      <td>29600</td>\n",
       "      <td>29720</td>\n",
       "      <td>GUCUACUCUUGUGCAGAAUGAAUUCUCGUAACUACAUAGCACAAGU...</td>\n",
       "      <td>..((((..((((((.(((....)))...[[[[[[[[[.))))))))...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>338</th>\n",
       "      <td>338</td>\n",
       "      <td>29640</td>\n",
       "      <td>29760</td>\n",
       "      <td>ACAAGUAGAUGUAGUUAACUUUAAUCUCACAUAGCAAUCUUUAAUC...</td>\n",
       "      <td>((((((.[[[[[[....................................</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>339 rows Ã— 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Unnamed: 0  start    end  \\\n",
       "0             0     40    160   \n",
       "1             1    120    240   \n",
       "2             2    360    480   \n",
       "3             3    400    520   \n",
       "4             4    440    560   \n",
       "..          ...    ...    ...   \n",
       "334         334  29480  29600   \n",
       "335         335  29520  29640   \n",
       "336         336  29560  29680   \n",
       "337         337  29600  29720   \n",
       "338         338  29640  29760   \n",
       "\n",
       "                                              sequence  \\\n",
       "0    UUUCGAUCUCUUGUAGAUCUGUUCUCUAAACGAACUUUAAAAUCUG...   \n",
       "1    CACGCAGUAUAAUUAAUAACUAAUUACUGUCGUUGACAGGACACGA...   \n",
       "2    AGACUCCGUGGAGGAGGUCUUAUCAGAGGCACGUCAACAUCUUAAA...   \n",
       "3    CUUAAAGAUGGCACUUGUGGCUUAGUAGAAGUUGAAAAAGGCGUUU...   \n",
       "4    GCGUUUUGCCUCAACUUGAACAGCCCUAUGUGUUCAUCAAACGUUC...   \n",
       "..                                                 ...   \n",
       "334  UCUCCAAACAAUUGCAACAAUCCAUGAGCAGUGCUGACUCAACUCA...   \n",
       "335  AACUCAGGCCUAAACUCAUGCAGACCACACAAGGCAGAUGGGCUAU...   \n",
       "336  GGCUAUAUAAACGUUUUCGCUUUUCCGUUUACGAUAUAUAGUCUAC...   \n",
       "337  GUCUACUCUUGUGCAGAAUGAAUUCUCGUAACUACAUAGCACAAGU...   \n",
       "338  ACAAGUAGAUGUAGUUAACUUUAAUCUCACAUAGCAAUCUUUAAUC...   \n",
       "\n",
       "                                                struct  \n",
       "0    ....(((((.....))))).........................(....  \n",
       "1    .((....((..(((.......)))))[[[[[)).]]]]]...((((...  \n",
       "2    ((((((([[[..)))).))).........]]].....((((((.))...  \n",
       "3    ......((.....(....((((......((((((....(((((......  \n",
       "4    .((((.[[[[.[[[[[((((((........))))))...))))......  \n",
       "..                                                 ...  \n",
       "334  ............(.........[[[[[[[)...(((((....))))...  \n",
       "335  ...........................(((((((....((((((((...  \n",
       "336  ((((((((((([[[.............)).]]].)))))))))(.....  \n",
       "337  ..((((..((((((.(((....)))...[[[[[[[[[.))))))))...  \n",
       "338  ((((((.[[[[[[....................................  \n",
       "\n",
       "[339 rows x 5 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spotrna = pd.read_csv('/home/gnye8/Desktop/PK_research/pipeline_results/direct_output/spotrna.csv')\n",
    "spotrna"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ea1a2fd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1da69d77",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
