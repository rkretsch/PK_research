{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "02f9f865",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_average_consensus(starts_all_programs, bp_lists_all_programs):\n",
    "    avg_consensus = []\n",
    "    #starts with a list of locations from a single predictor (\"predictor A\") \n",
    "    for idx1, program1_starts in enumerate(starts_all_programs):\n",
    "        #retrieves the bp_lists from predictor A\n",
    "        program1_bp_lists = bp_lists_all_programs[idx1]\n",
    "        program1_consensus_scores = []\n",
    "        #takes a second list of locations (from a different predictor, \"predictor B\")\n",
    "        for idx2, program2_starts in enumerate(starts_all_programs):\n",
    "            #checks to make sure that predictor A and B are not the same\n",
    "            if idx1 != idx2:\n",
    "                #retrieves the bp_lists from predictor B\n",
    "                program2_bp_lists = bp_lists_all_programs[idx2]\n",
    "                #generates a list of scores for predictor A and how well its bp_lists agree with predictor B\n",
    "                consensus_scores = get_consensus_scores(program1_starts, program1_bp_lists, \n",
    "                                                        program2_starts, program2_bp_lists)\n",
    "                program1_consensus_scores.append(consensus_scores)\n",
    "\n",
    "        program1_avgs = []\n",
    "        # now, the three scores generated for pk1 from predictor A are averaged together into a single score for pk1\n",
    "        for i in range(len(program1_consensus_scores[0])):\n",
    "            window = []\n",
    "            for program in program1_consensus_scores:\n",
    "                window.append(program[i])\n",
    "            avg_score = sum(window)/len(window)\n",
    "            program1_avgs.append(avg_score)\n",
    "            \n",
    "        # the list program1_avgs contains the final averaged scores for pk1, pk2, and pk3\n",
    "        avg_consensus.append(program1_avgs)\n",
    "        \n",
    "    return avg_consensus\n",
    "\n",
    "def get_consensus_scores(program1_starts, bp_lists1, program2_starts, bp_lists2):\n",
    "    scores = []\n",
    "    for i, start1 in enumerate(program1_starts):\n",
    "        for idx, start2 in enumerate(program2_starts):\n",
    "            if start1 == start2:\n",
    "                # retrieves consensus score for that structure\n",
    "                bp_list_score = compare_bp_lists(bp_lists1[i], bp_lists2[idx])\n",
    "                scores.append(bp_list_score)\n",
    "    return scores\n",
    "\n",
    "def compare_bp_lists(bp_list1, bp_list2):\n",
    "    bp_list_score = 0\n",
    "    for bp1 in bp_list1: \n",
    "        for bp2 in bp_list2: \n",
    "            if bp1 == bp2: \n",
    "                bp_list_score += 1\n",
    "        # divide by total number of base pairs in bp_list1 to normalize results\n",
    "    score = 0\n",
    "    if len(bp_list1) == 0:\n",
    "        score = score + (bp_list_score/1)\n",
    "    else:\n",
    "        score = score + (bp_list_score/len(bp_list1))\n",
    "    return score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "70b5a697",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0, 100, 200], [0, 100, 200], [0, 100, 200]]\n",
      "[[[[1, 8], [2, 7], [4, 12], [5, 11]], [[1, 8], [2, 7], [4, 12]], [[0, 9], [1, 8], [3, 12], [4, 11], [5, 10]]], [[[1, 8], [2, 7], [4, 12], [5, 11]], [[1, 9], [2, 8], [3, 7]], [[0, 12], [1, 11], [3, 9], [4, 8], [5, 7]]], [[[1, 8], [2, 7], [5, 11]], [[1, 9], [2, 8], [3, 7]], []]]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "predictorA_starts = [0, 100, 200]\n",
    "predictorA_dotbracket = ['.((.[[.))..]]', '.((.[..))...]', '((.[[[..))]]]']\n",
    "predictorA_bplist = [[[1,8],[2,7],[4,12],[5,11]], [[1,8],[2,7],[4,12]], [[0,9],[1,8],[3,12],[4,11],[5,10]]]\n",
    "\n",
    "predictorB_starts = [0, 100, 200]\n",
    "predictorB_dotbracket = ['.((.[[.))..]]', '.(((...)))...', '((.(((.))).))']\n",
    "predictorB_bplist = [[[1,8],[2,7],[4,12],[5,11]], [[1,9],[2,8],[3,7]], [[0,12],[1,11],[3,9],[4,8],[5,7]]]\n",
    "\n",
    "predictorC_starts = [0, 100, 200]\n",
    "predictorC_dotbracket = ['.((..[.))..].', '.(((...)))...', '.............']\n",
    "predictorC_bplist = [[[1,8],[2,7],[5,11]], [[1,9],[2,8],[3,7]], []]\n",
    "\n",
    "# now putting everything together into proper formats for the functions:\n",
    "\n",
    "test_starts_all_programs = [predictorA_starts, predictorB_starts, predictorC_starts]\n",
    "test_bp_lists_all_programs = [predictorA_bplist, predictorB_bplist, predictorC_bplist]\n",
    "print(test_starts_all_programs)\n",
    "print(test_bp_lists_all_programs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d7e460cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.875, 0.0, 0.0], [0.875, 0.5, 0.0], [1.0, 0.5, 0.0]]\n"
     ]
    }
   ],
   "source": [
    "test_avg_consensus = get_average_consensus(test_starts_all_programs,test_bp_lists_all_programs)\n",
    "print(test_avg_consensus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3aec5c4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
